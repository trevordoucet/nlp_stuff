{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, TrainingArguments, Trainer\n",
    "import nltk\n",
    "import os\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt', quiet=True)\n",
    "nltk.data.path.append('/Users/trevordoucet/nltk_data')\n",
    "os.environ['NLTK_DATA'] = '/Users/trevordoucet/nltk_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pre-Trained Model & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39450"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/final_descriptions.xlsx')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 31560/31560 [00:07<00:00, 4284.46 examples/s]\n",
      "Map: 100%|██████████| 3945/3945 [00:01<00:00, 3604.91 examples/s]\n",
      "Map: 100%|██████████| 3945/3945 [00:01<00:00, 3508.24 examples/s]\n",
      "/var/folders/c9/nckl2xts1ys2_knbj2y1562h0000gn/T/ipykernel_16855/1654167144.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1973' max='1973' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1973/1973 02:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 3.288257598876953, 'eval_model_preparation_time': 0.0022, 'eval_runtime': 146.5729, 'eval_samples_per_second': 26.915, 'eval_steps_per_second': 13.461}\n",
      "Perplexity: 26.79613334341583\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Huggingface df\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Splitting the dataset into train, validation, and test sets\n",
    "split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "test_validation = split_dataset['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": split_dataset['train'],\n",
    "    \"validation\": test_validation['train'],\n",
    "    \"test\": test_validation[\"test\"]\n",
    "})\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(examples):\n",
    "    model_inputs = tokenizer(examples[\"two_sentence_summary\"], max_length=256, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess, batched=True, remove_columns=['two_sentence_summary'])\n",
    "\n",
    "# Training arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results_overview\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    logging_dir=\"./logs_overview\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(\"Evaluation results:\", results)\n",
    "\n",
    "eval_loss = results['eval_loss']\n",
    "perplexity = math.exp(eval_loss)\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../saved_overview_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trevordoucet/Library/Python/3.9/lib/python/site-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model load\n",
    "model_name = \"../saved_overview_model\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name, local_files_only=True)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "A kid's imaginary friend returns years later with a real body and a warning.\n",
      "Generated Text:\n",
      "A kid's imaginary friend returns years later with a real body and a warning. A kid’s imaginary friends returns with an imaginary body. The child's friend is a man named David.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt:\n",
      "An android nanny begins to question her programming after reading poetry.\n",
      "Generated Text:\n",
      "An android nanny begins to question her programming after reading poetry. The android is a nannie who works for a family of five. She is also a teacher and a nurse. Her name is Nanny.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt:\n",
      "A haunted ship appears off the coast every full moon—and takes one passenger.\n",
      "Generated Text:\n",
      "A haunted ship appears off the coast every full moon. The ship takes one passenger. It's a ghost ship. But it's not dangerous. Just look at the pictures. They're not scary.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Movie concepts\n",
    "prompts = [\n",
    "    \"A kid's imaginary friend returns years later with a real body and a warning.\",\n",
    "    \"An android nanny begins to question her programming after reading poetry.\",\n",
    "    \"A haunted ship appears off the coast every full moon—and takes one passenger.\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    # Encoding\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=256, truncation=True)\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    \n",
    "    # Generate text\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=60,\n",
    "        min_length=40,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        no_repeat_ngram_size=2,\n",
    "        temperature=0.01\n",
    "    )\n",
    "\n",
    "    # Decoding\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remove repeated pieces\n",
    "    split_prompt = prompt.split(\":\", 1)  \n",
    "    if len(split_prompt) == 2:\n",
    "        story_part = split_prompt[1].strip() \n",
    "        if generated_text.startswith(story_part):\n",
    "            generated_text = generated_text[len(story_part):].strip()\n",
    "\n",
    "    print(\"Prompt:\")\n",
    "    print(prompt)\n",
    "    print(\"Generated Text:\")\n",
    "    print(generated_text)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results outputting to ../output_summaries/generated_movie_overviews.xlsx\n"
     ]
    }
   ],
   "source": [
    "prompts_df = pd.read_csv(\"../data/prompts/generated_prompts.csv\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Alternative parameters for temperatures, min and max lengths\n",
    "temperatures = [0.01, 0.5, 0.8]\n",
    "min_lengths = [40, 50]\n",
    "max_lengths = [60, 80]\n",
    "\n",
    "# Loop over each prompt and parameter combination\n",
    "for prompt in prompts_df[\"Movie Prompt\"]:\n",
    "    for temp in temperatures:\n",
    "        for min_len in min_lengths:\n",
    "            for max_len in max_lengths:\n",
    "                if max_len <= min_len:\n",
    "                    continue\n",
    "\n",
    "                # Encoding\n",
    "                input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=256, truncation=True)\n",
    "\n",
    "                # Generate\n",
    "                outputs = model.generate(\n",
    "                    input_ids,\n",
    "                    max_length=max_len,\n",
    "                    min_length=min_len,\n",
    "                    do_sample=True,\n",
    "                    top_k=50,\n",
    "                    top_p=0.95,\n",
    "                    no_repeat_ngram_size=2,\n",
    "                    temperature=temp\n",
    "                )\n",
    "\n",
    "                # Decoding\n",
    "                generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "                results.append({\n",
    "                    \"Prompt\": prompt,\n",
    "                    \"Temperature\": temp,\n",
    "                    \"Min Length\": min_len,\n",
    "                    \"Max Length\": max_len,\n",
    "                    \"Generated Summary\": generated_text\n",
    "                })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "file_path = \"../output_summaries/generated_movie_overviews.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(file_path) as writer:\n",
    "    for (temp, min_len, max_len), group in df_results.groupby([\"Temperature\", \"Min Length\", \"Max Length\"]):\n",
    "        sheet_name = f\"T{temp}_min{min_len}_max{max_len}\"\n",
    "        group.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Results outputting to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity analysis from generated text and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Generated Summary  \\\n",
      "0   A former astronaut opens a roadside diner to r...   \n",
      "1   A teenage hacker discovers an AI that claims t...   \n",
      "2   A mail carrier uncovers decades of unsent love...   \n",
      "3   Two rival magicians are forced to team up to s...   \n",
      "4   An elderly librarian finds a book that predict...   \n",
      "..                                                ...   \n",
      "90  A child’s imaginary friend recruits them for a...   \n",
      "91  A brother and sister inherit a hotel where the...   \n",
      "92  A scientist’s experiment goes wrong, freezing ...   \n",
      "93  A single mom’s new houseplant starts whisperin...   \n",
      "94  A man finds a library where each book is someo...   \n",
      "\n",
      "                           Final Two Sentence Summary  \\\n",
      "0   A rural roadside diner becomes the host of a m...   \n",
      "1   A mental patient with a heart problem, Xu Lian...   \n",
      "2   The recovery of a mail bag stolen in a robbery...   \n",
      "3   Captured by smugglers when he was just a hatch...   \n",
      "4   In a futuristic city sharply divided between t...   \n",
      "..                                                ...   \n",
      "90  After discovering she can see everyone's imagi...   \n",
      "91  Uncle Claude comes to the Ardmore Beach Hotel ...   \n",
      "92  Rajesh is a scientist. He is injured following...   \n",
      "93  A shy and timid man who lives with his mother ...   \n",
      "94  The film is set in Delhi, where a widowed moth...   \n",
      "\n",
      "              Best Match Title  Similarity Score  \n",
      "0                   Last Straw          0.240701  \n",
      "1                Bunshinsaba 3          0.284026  \n",
      "2            Fate Takes a Hand          0.277278  \n",
      "3                          Rio          0.187902  \n",
      "4                   Metropolis          0.224565  \n",
      "..                         ...               ...  \n",
      "90                          IF          0.296495  \n",
      "91               So Long Letty          0.222777  \n",
      "92                      Yakeen          0.294815  \n",
      "93  Please Don't Eat My Mother          0.201324  \n",
      "94             Listen... Amaya          0.230295  \n",
      "\n",
      "[95 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "generated_df = pd.read_excel(\"../output_summaries/generated_movie_overviews.xlsx\", sheet_name=\"T0.01_min40_max60\")\n",
    "final_df = pd.read_excel(\"../data/final_descriptions.xlsx\")\n",
    "final_df[\"Combined Summary\"] = final_df[\"two_sentence_summary\"]\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "all_texts = list(generated_df[\"Generated Summary\"]) + list(final_df[\"Combined Summary\"])\n",
    "vectorizer.fit(all_texts)\n",
    "generated_vectors = vectorizer.transform(generated_df[\"Generated Summary\"])\n",
    "final_vectors = vectorizer.transform(final_df[\"Combined Summary\"])\n",
    "\n",
    "# Cosine similarity\n",
    "similarity_matrix = cosine_similarity(generated_vectors, final_vectors)\n",
    "\n",
    "# Matches\n",
    "highest_matches = []\n",
    "for i, sim_row in enumerate(similarity_matrix):\n",
    "    max_index = sim_row.argmax()\n",
    "    max_score = sim_row[max_index]\n",
    "    movie_title = final_df.iloc[max_index][\"title\"]\n",
    "    final_summary = final_df.iloc[max_index][\"two_sentence_summary\"]\n",
    "    highest_matches.append({\n",
    "        \"Generated Summary\": generated_df.iloc[i][\"Generated Summary\"],\n",
    "        \"Final Two Sentence Summary\": final_summary,\n",
    "        \"Best Match Title\": movie_title,\n",
    "        \"Similarity Score\": max_score\n",
    "    })\n",
    "\n",
    "\n",
    "highest_df = pd.DataFrame(highest_matches)\n",
    "highest_df.to_excel(\"../output_summaries/summary_similarity_results.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
